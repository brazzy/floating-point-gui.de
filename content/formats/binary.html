--- 
title: Binary Fractions
---

As a programmer, you are familiar with the concept of binary integers, i.e.
the representation of integer numbers as a series of bits:

<table>
<tr><th colspan="9">Decimal (<span class="num_base">base 10</span>)</th><th></th><th colspan="17">Binary (<span class="num_base">base 2</span>)</th></tr>
<tr class="base_example">
<td class="digit">1</td><td>&sdot;</td><td class="num_base">10<sup>1</sup></td><td>+</td>
<td class="digit">3</td><td>&sdot;</td><td class="num_base">10<sup>0</sup></td><td>=</td>
<td class="digit">13<sub class="num_base">10</sub></td><td class="separator">=</td>
<td class="digit">1101<sub class="num_base">2</sub></td><td>=</td>
<td class="digit">1</td><td>&sdot;</td><td class="num_base">2<sup>3</sup></td><td>+</td>
<td class="digit">1</td><td>&sdot;</td><td class="num_base">2<sup>2</sup></td><td>+</td>
<td class="digit">0</td><td>&sdot;</td><td class="num_base">2<sup>1</sup></td><td>+</td>
<td class="digit">1</td><td>&sdot;</td><td class="num_base">2<sup>0</sup></td>
</tr><tr class="base_example">
<td class="digit">1</td><td>&sdot;</td><td>10</td><td>+</td>
<td class="digit">3</td><td>&sdot;</td><td>1 </td><td>=</td>
<td class="digit">13<sub class="num_base">10</sub></td><td class="separator">=</td>
<td class="digit">1101<sub class="num_base">2</sub></td><td>=</td>
<td class="digit">1</td><td>&sdot;</td><td>8</td><td>+</td>
<td class="digit">1</td><td>&sdot;</td><td>4</td><td>+</td>
<td class="digit">0</td><td>&sdot;</td><td>2</td><td>+</td>
<td class="digit">1</td><td>&sdot;</td><td>0</td>
</tr></table>

This is how computers store integer numbers internally. And for fractional numbers in [positional notation](http://en.wikipedia.org/wiki/Positional_notation), they do the same thing:

<table>
<tr><th colspan="13">Decimal (<span class="num_base">base 10</span>)</th><th></th><th colspan="13">Binary (<span class="num_base">base 2</span>)</th></tr>
<tr class="base_example">
<td class="digit">6</td><td>&sdot;</td><td class="num_base">10<sup>-1</sup></td><td>+</td>
<td class="digit">2</td><td>&sdot;</td><td class="num_base">10<sup>-2</sup></td><td>+</td>
<td class="digit">5</td><td>&sdot;</td><td class="num_base">10<sup>-3</sup></td><td>=</td>
<td class="digit">0.625<sub class="num_base">10</sub></td><td class="separator">=</td>
<td class="digit">0.101<sub class="num_base">2</sub></td><td>=</td>
<td class="digit">1</td><td>&sdot;</td><td class="num_base">2<sup>-1</sup></td><td>+</td>
<td class="digit">0</td><td>&sdot;</td><td class="num_base">2<sup>-2</sup></td><td>+</td>
<td class="digit">1</td><td>&sdot;</td><td class="num_base">2<sup>-3</sup></td>
</tr><tr class="base_example">
<td class="digit">6</td><td>&sdot;</td><td>1/10</td><td>+</td>
<td class="digit">2</td><td>&sdot;</td><td>1/100</td><td>+</td>
<td class="digit">5</td><td>&sdot;</td><td>1/1000</td><td>=</td>
<td class="digit">0.625<sub class="num_base">10</sub></td><td class="separator">=</td>
<td class="digit">0.101<sub class="num_base">2</sub></td><td>=</td>
<td class="digit">1</td><td>&sdot;</td><td>1/2</td><td>+</td>
<td class="digit">0</td><td>&sdot;</td><td>1/4</td><td>+</td>
<td class="digit">1</td><td>&sdot;</td><td>1/8</td>
</tr></table>

Both decimal and binary (and any other base as well) can represent only those fractions in a 
finite positional notation where the denominator of the fraction has only prime factors that 
also occur in the base. For example, in decimal 1/4, 3/5 and 8/20 are finite, because 2 and 5 are the prime factors of 10. But 1/3 is not finite, nor is 2/3 or 1/7 or 4/6, because 3 and 7 are not factors of 10.

Similarly, in binary only those fractions are finite that are a (finite) sum of negative
powers of two. Unfortunately, this does not include most of the numbers that can be 
represented as finite fration in base 10, like 0.1 - and there you are. Since computer 
memory is limited, infinite fractions have to be cut off after some point:

| Fraction | Base | Positional Notation | Rounded to 4 digits| Rounded value as fraction | Rounding error |
|-|-|-|-|
| 1/10 | 10 | 0.1 | 0.1 | 1/10 | 0 |
| 1/3  | 10 | 0.<span class="over">3</span> | 0.3333 | 3333/10000 | 1/30000 |
| 1/2  | 2  | 0.1 | 0.1 | 1/2 | 0 |
| 1/10 | 2  | 0.<span class="over">00011</span> | 0.0001 | 1/16 | 3/80 |

And this is how you already get a rounding error when you just *write down* a number like 0.1 and
run it through your interpreter or compiler. It's not as big as 3/80 and may be invisible because
computers cut off after 23 or 52 binary digits rather than 4. Which leads us to the next concept...
